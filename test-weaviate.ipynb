{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG\n",
    "\n",
    "This notebook is looking to use a vector db to create a Retrieval-Augmented Generation (RAG) model by optimizing LLM output trough an authorized knowledge base.\n",
    "\n",
    "We are going to take the following approach:\n",
    "1. Set up\n",
    "  a. Problem definition\n",
    "  b. Data\n",
    "  c. Package stack\n",
    "2. Connection\n",
    "3. Data\n",
    "4. Modelling\n",
    "5. RAG Setup\n",
    "6. Evaluation\n",
    "\n",
    "## 1. Setup\n",
    "### 1.1. Problem definition\n",
    "In a statement\n",
    "> Giving a book in a plain text format, are we able to answer simple related-questions to the book?\n",
    "\n",
    "### 1.2. Data\n",
    "The authorized knowledge base is \"Harry Potter 1\" by \"J.K. Rowling\" retrieved from [Kaggle - Harry Potter Books](https://www.kaggle.com/datasets/santiviquez/hp1txt) for learning purposes.\n",
    "\n",
    "### 1.3 Package stack\n",
    "- `pip install weaviate-client transformers accelerate sentence-transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from weaviate.classes.init import Auth\n",
    "from weaviate.classes.config import Property, DataType\n",
    "import numpy as np\n",
    "import weaviate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidflores/RAG-projects/weaviate/rag-one-demo/.venv/lib/python3.12/site-packages/weaviate/warnings.py:314: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
      "            Please make sure to close the connection using `client.close()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* succesfull conection\n",
      "* collection created\n"
     ]
    }
   ],
   "source": [
    "# --- 2.1: Initialize Weaviate ---\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=os.environ[\"WEAVIATE_URL\"],\n",
    "    auth_credentials=Auth.api_key(os.environ[\"WEAVIATE_API_KEY\"]),\n",
    ")\n",
    "\n",
    "if client.is_ready():\n",
    "  client.connect()\n",
    "  print('* succesfull conection')\n",
    "\n",
    "if not client.collections.exists(\"TextChunk\"):\n",
    "  client.collections.create(\n",
    "    name=\"TextChunk\",\n",
    "    description=\"A chunk of text from a book\",\n",
    "    properties=[\n",
    "        Property(name='content', data_type=DataType.TEXT)\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  print(\"* collection created\")\n",
    "else :\n",
    "  print(\"* collection already exist\")\n",
    "\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data\n",
    "### --- 3.1: Load plain text book ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/document.txt\", \"r\") as f:\n",
    "    book_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- 3.2: Load the Textbook and Split into Chunks ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(text, max_length=500):\n",
    "    \"\"\"Splits text into chunks of specified max length.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for word in words:\n",
    "        if current_length + len(word) <= max_length:\n",
    "            current_chunk.append(word)\n",
    "            current_length += len(word) + 1\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = len(word) + 1\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_into_chunks(book_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- 3.3: Embed and Upload Chunks to Weaviate ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book chunks uploaded to Weaviate!\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Use a small and efficient model\n",
    "\n",
    "collection_object = client.collections.get(\"TextChunk\")\n",
    "\n",
    "for chunk in chunks:\n",
    "    vector = model.encode(chunk).tolist()\n",
    "    props = {\"content\": chunk}\n",
    "    collection_object.data.insert(properties=props, vector=vector)\n",
    "\n",
    "print(\"Book chunks uploaded to Weaviate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "### --- 4.1: Set Up Local QA Model ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Error while downloading from https://cdn-lfs.hf.co/repos/16/41/16418edd56a7c42307a0f361531c01ee227a92a98628972bd433062c276dad7c/99196ddfbe886e8ef860f52de979df64890edfc792c3d94ce0502991f347dd18?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1735238982&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTIzODk4Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xNi80MS8xNjQxOGVkZDU2YTdjNDIzMDdhMGYzNjE1MzFjMDFlZTIyN2E5MmE5ODYyODk3MmJkNDMzMDYyYzI3NmRhZDdjLzk5MTk2ZGRmYmU4ODZlOGVmODYwZjUyZGU5NzlkZjY0ODkwZWRmYzc5MmMzZDk0Y2UwNTAyOTkxZjM0N2RkMTg%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=tYc-3mjaLMeQdF2Axznfs4V6Ms9NqQva%7Enhd-wVtBZJG4irdkzrxM2q4cSIME4BFLpD8rb4fjV0O1YfWmzQd03F%7EQnSV9UJyH1sNgvdyhrZMbLQr3Tu8WwfYTFYqmrJ%7Efc0%7Egy%7Eruak-DxhPxvCFZ%7EU5471jV1d8JmcLxGwOFp--mKhHPkwsEdArcS8hocVWl4Eyy-RFG9G1np%7EwvwJtpvGqEwV4s%7ErbL8CRHP1SmZS6xBEm3AuOqqiTobZbxlOq7TE4WgKshvINCQbX5nzQuswjIN6paC7z%7EN5r64XpL3yKVoGSIziEhb%7EaTDEUBOACICACk9lNmlv-lEuakTYRpw__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Downloading shards: 100%|██████████| 2/2 [26:50<00:00, 805.29s/it] \n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:875: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=85 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:875: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=87 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.57s/it]\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Efficient QA model\n",
    "# qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")  # Try 1: ...\n",
    "# qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-Large\")  # Try 2: 3m 47s\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-xl\")  # Try 3: 26m 59s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RAG Setup\n",
    "### --- 5.1: RAG System Functions ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query, top_k=3):\n",
    "    \"\"\"Retrieve the most relevant text chunks from a collection in Weaviate.\"\"\"\n",
    "    query_vector = model.encode(query).tolist()\n",
    "    collection = client.collections.get(\"TextChunk\")\n",
    "    chunks = []\n",
    "\n",
    "    # Iterate through the collection and rank based on vector similarity\n",
    "    for item in collection.iterator(include_vector=True):\n",
    "        content = item.properties[\"content\"]\n",
    "        vector = item.vector[\"default\"]\n",
    "        \n",
    "        # Calculate similarity (cosine similarity or equivalent)\n",
    "        similarity = cosine_similarity([query_vector], [vector])[0][0]\n",
    "        chunks.append((content, similarity))\n",
    "\n",
    "    # Sort chunks by similarity and return the top_k\n",
    "    chunks = sorted(chunks, key=lambda x: x[1], reverse=True)\n",
    "    top_chunks = [chunk[0] for chunk in chunks[:top_k]]\n",
    "    \n",
    "    # Debug: Check retrieved chunks\n",
    "    print(\"\\nRetrieved Chunks:\")\n",
    "    for i, chunk in enumerate(top_chunks):\n",
    "        print(f\"Chunk {i + 1}: {chunk[:100]}...\")  # Show first 100 characters of each chunk\n",
    "\n",
    "    return top_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(query):\n",
    "    \"\"\"Answer a question by retrieving relevant chunks and generating an answer.\"\"\"\n",
    "    top = 5\n",
    "    relevant_chunks = retrieve_relevant_chunks(query, top_k=top)\n",
    "    context = \"\\n\".join(relevant_chunks[:top])  # Limit context to top chunks\n",
    "\n",
    "    # Debug: Check context\n",
    "    print(\"\\nGenerated Context for QA:\")\n",
    "    print(context)\n",
    "\n",
    "    # Combine context and question into a structured prompt\n",
    "    prompt = f\"\"\"\n",
    "        You are an helpfull assistant. Use the following context from a book to answer the user's question.\n",
    "        Only if you don't know the answer just say that you need more information.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Use 5 sentences minimum and keep the answer concise and accurate.\n",
    "\n",
    "        Question: {query}\n",
    "        Answer:\"\"\"\n",
    "    \n",
    "    # Use the local Hugging Face model to generate an answer\n",
    "    response = qa_pipeline(prompt, max_length=200, truncation=True)\n",
    "    \n",
    "    # Handle short or unhelpful answers\n",
    "    if len(response[0]['generated_text']) < 10:  # If the answer is too short\n",
    "        fallback_chunk = relevant_chunks[0]  # Use the most relevant chunk\n",
    "        return f\"{response[0]['generated_text']} (Additional context: {fallback_chunk[:200]}...)\"\n",
    "\n",
    "    return response[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- 6.1: Test the RAG System ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions\n",
    "questions = [\n",
    "  # questions in the scoped data\n",
    "  \"What is the main theme of the book?\", # 0\n",
    "  \"What is the main theme of the book?\", # 1\n",
    "  \"Who is Harry Potter?\", # 2\n",
    "  \"What is the main threat?\", # 3\n",
    "  \"What is the moral of this story?\", # 4\n",
    "  \"Who are the main characters?\", # 5\n",
    "  \"Who are harry potter friends?\", # 6\n",
    "\n",
    "  # questions out the scoped data\n",
    "  \"Who is Bellatrix Lestrange?\", # 7\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Retrieved Chunks:\n",
      "Chunk 1: the creeps. The Restricted Section was right at the back of the library. Step ping carefully over th...\n",
      "Chunk 2: young as you, I'm sure it seems incredible, but to Nicolas and Perenelle, it really is like going to...\n",
      "Chunk 3: plates. But from that moment on, Hermione Granger became their friend. There are some things you can...\n",
      "Chunk 4: Developments in Wizardry. And then, of course, there was the sheer size of the library; tens of thou...\n",
      "Chunk 5: from one of the teachers to look in any of the restricted books, and he knew he'd never get one. The...\n",
      "\n",
      "Generated Context for QA:\n",
      "the creeps. The Restricted Section was right at the back of the library. Step ping carefully over the rope that separated these books from the rest of the library, he held up his lamp to read the titles. They didn't tell him much. Their peeling, faded gold letters spelled words in languages Harry couldn't understand. Some had no title at all. One book had a dark stain on it that looked horribly like blood. The hairs on the back of Harry's neck prickled. Maybe he was imagining it, maybe not, but\n",
      "young as you, I'm sure it seems incredible, but to Nicolas and Perenelle, it really is like going to bed after a very, very long day. After all, to the well-organized mind, death is but the next great adventure. You know, the Stone was really not such a wonderful thing. As much money and life as you could want! The two things most human beings would choose above all -- the trouble is, humans do have a knack of choosing precisely those things that are worst for them.\" Harry lay there, lost for\n",
      "plates. But from that moment on, Hermione Granger became their friend. There are some things you can't share without ending up liking each other, and knocking out a twelve-foot mountain troll is one of them. CHAPTER ELEVEN QUIDDITCH As they entered November, the weather turned very cold. The mountains around the school became icy gray and the lake like chilled steel. Every morning the ground was covered in frost. Hagrid could be seen from the upstairs windows defrosting broomsticks on the\n",
      "Developments in Wizardry. And then, of course, there was the sheer size of the library; tens of thousands of books; thousands of shelves; hundreds of narrow rows. Hermione took out a list of subjects and titles she had decided to search while Ron strode off down a row of books and started pulling them off the shelves at random. Harry wandered over to the Restricted Section. He had been wondering for a while if Flamel wasn't somewhere in there. Unfortunately, you needed a specially signed note\n",
      "from one of the teachers to look in any of the restricted books, and he knew he'd never get one. These were the books containing powerful Dark Magic never taught at Hogwarts, and only read by older students studying advanced Defense Against the Dark Arts. \"What are you looking for, boy?\" \"Nothing,\" said Harry. Madam Pince the librarian brandished a feather duster at him. \"You'd better get out, then. Go on -- out!\" Wishing he'd been a bit quicker at thinking up some story, Harry left the library.\n",
      "\n",
      "\u001b[4m\u001b[1mQuestion: What is the main theme of the book?\u001b[0m\n",
      "\u001b[1m\u001b[92m Answer: \u001b[0mHarry was a wizard\n"
     ]
    }
   ],
   "source": [
    "# Answer a question in the scope\n",
    "client.connect()\n",
    "if __name__ == \"__main__\" and client.is_ready():\n",
    "  questionNo = 0\n",
    "  answer = answer_question(questions[questionNo])\n",
    "  print(\"\")\n",
    "  print(f\"{bcolors.UNDERLINE + bcolors.BOLD}Question: {questions[questionNo]}{bcolors.ENDC}\")\n",
    "  print(f\"{bcolors.BOLD + bcolors.OKGREEN} Answer: {bcolors.ENDC}{answer}\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Retrieved Chunks:\n",
      "Chunk 1: pointing at two large ice creams to show he couldn't come in. \"That's Hagrid,\" said Harry, pleased t...\n",
      "Chunk 2: bought him (chocolate and raspberry with chopped nuts). \"What's up?\" said Hagrid. \"Nothing,\" Harry l...\n",
      "Chunk 3: looked like bodyguards. \"Oh, this is Crabbe and this is Goyle,\" said the pale boy carelessly, notici...\n",
      "Chunk 4: as he unwrapped the frog. \"Thanks, Harry... I think I'll go to bed.... D'you want the card, you coll...\n",
      "Chunk 5: These people will never understand him! He'll be famous -- a legend -- I wouldn't be surprised if to...\n",
      "\n",
      "Generated Context for QA:\n",
      "pointing at two large ice creams to show he couldn't come in. \"That's Hagrid,\" said Harry, pleased to know something the boy didn't. \"He works at Hogwarts.\" \"Oh,\" said the boy, \"I've heard of him. He's a sort of servant, isn't he?\" \"He's the gamekeeper,\" said Harry. He was liking the boy less and less every second. \"Yes, exactly. I heard he's a sort of savage -- lives in a hut on the school grounds and every now and then he gets drunk, tries to do magic, and ends up setting fire to his bed.\" \"I\n",
      "bought him (chocolate and raspberry with chopped nuts). \"What's up?\" said Hagrid. \"Nothing,\" Harry lied. They stopped to buy parchment and quills. Harry cheered up a bit when he found a bottle of ink that changed color as you wrote. When they had left the shop, he said, \"Hagrid, what's Quidditch?\" \"Blimey, Harry, I keep forgettin' how little yeh know -- not knowin' about Quidditch!\" \"Don't make me feel worse,\" said Harry. He told Hagrid about the pate boy in Madam Malkin's. \"--and he said people\n",
      "looked like bodyguards. \"Oh, this is Crabbe and this is Goyle,\" said the pale boy carelessly, noticing where Harry was looking. \"And my name's Malfoy, Draco Malfoy.\" Ron gave a slight cough, which might have been hiding a snigget. Draco Malfoy looked at him. \"Think my name's funny, do you? No need to ask who you are. My father told me all the Weasleys have red hair, freckles, and more children than they can afford.\" He turned back to Harry. \"You'll soon find out some wizarding families are much\n",
      "as he unwrapped the frog. \"Thanks, Harry... I think I'll go to bed.... D'you want the card, you collect them, don't you?\" As Neville walked away, Harry looked at the Famous Wizard card. \"Dumbledore again,\" he said, \"He was the first one I ever-\" He gasped. He stared at the back of the card. Then he looked up at Ron and Hermione. \"I've found him!\" he whispered. \"I've found Flamel! I told you I'd read the name somewhere before, I read it on the train coming here -- listen to this: 'Dumbledore is\n",
      "These people will never understand him! He'll be famous -- a legend -- I wouldn't be surprised if today was known as Harry Potter day in the future -- there will be books written about Harry -- every child in our world will know his name!\" \"Exactly,\" said Dumbledore, looking very seriously over the top of his half-moon glasses. \"It would be enough to turn any boy's head. Famous before he can walk and talk! Famous for something he won't even remember! CarA you see how much better off he'll be,\n",
      "\n",
      "\u001b[4m\u001b[1mQuestion: Who is Harry Potter?\u001b[0m\n",
      "\u001b[1m\u001b[92m Answer: \u001b[0mmore sane than others.\n"
     ]
    }
   ],
   "source": [
    "# Answer a question in the scope\n",
    "client.connect()\n",
    "if __name__ == \"__main__\" and client.is_ready():\n",
    "  questionNo = 2\n",
    "  answer = answer_question(questions[questionNo])\n",
    "  print(\"\")\n",
    "  print(f\"{bcolors.UNDERLINE + bcolors.BOLD}Question: {questions[questionNo]}{bcolors.ENDC}\")\n",
    "  print(f\"{bcolors.BOLD + bcolors.OKGREEN} Answer: {bcolors.ENDC}{answer}\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Retrieved Chunks:\n",
      "Chunk 1: his robes. Harry and Ron were delighted to hear Hagrid call Fitch \"that old git.\" \"An' as fer that c...\n",
      "Chunk 2: of Norbert. We'll have to risk it. And we have got the invisibility cloak, Malfoy doesn't know about...\n",
      "Chunk 3: \"What utter rubbish! How dare you tell such lies! Come on -- I shall see Professor Snape about you, ...\n",
      "Chunk 4: You-Know-Who disappeared. Said they'd been bewitched. My dad doesn't believe it. He says Malfoy's fa...\n",
      "Chunk 5: last chamber. There was already someone there -- but it wasn't Snape. It wasn't even Voldemort. CHAP...\n",
      "\n",
      "Generated Context for QA:\n",
      "his robes. Harry and Ron were delighted to hear Hagrid call Fitch \"that old git.\" \"An' as fer that cat, Mrs. Norris, I'd like ter introduce her to Fang sometime. D'yeh know, every time I go up ter the school, she follows me everywhere? Can't get rid of her -- Fitch puts her up to it.\" Harry told Hagrid about Snape's lesson. Hagrid, like Ron, told Harry not to worry about it, that Snape liked hardly any of the students. \"But he seemed to really hate me.\" \"Rubbish!\" said Hagrid. \"Why should he?\"\n",
      "of Norbert. We'll have to risk it. And we have got the invisibility cloak, Malfoy doesn't know about that.\" They found Fang, the boarhound, sitting outside with a bandaged tail when they went to tell Hagrid, who opened a window to talk to them. \"I won't let you in,\" he puffed. \"Norbert's at a tricky stage -- nothin' I can't handle.\" When they told him about Charlie's letter, his eyes filled with tears, although that might have been because Norbert had just bitten him on the leg. \"Aargh! It's all\n",
      "\"What utter rubbish! How dare you tell such lies! Come on -- I shall see Professor Snape about you, Malfoy!\" The steep spiral staircase up to the top of the tower seemed the easiest thing in the world after that. Not until they'd stepped out into the cold night air did they throw off the cloak, glad to be able to breathe properly again. Hermione did a sort of jig. \"Malfoy's got detention! I could sing!\" \"Don't,\" Harry advised her. Chuckling about Malfoy, they waited, Norbert thrashing about in\n",
      "You-Know-Who disappeared. Said they'd been bewitched. My dad doesn't believe it. He says Malfoy's father didn't need an excuse to go over to the Dark Side.\" He turned to Hermione. \"Can we help you with something?\" \"You'd better hurry up and put your robes on, I've just been up to the front to ask the conductor, and he says we're nearly there. You haven't been fighting, have you? You'll be in trouble before we even get there!\" \"Scabbers has been fighting, not us,\" said Ron, scowling at her.\n",
      "last chamber. There was already someone there -- but it wasn't Snape. It wasn't even Voldemort. CHAPTER SEVENTEEN THE MAN WITH TWO FACES It was Quirrell. \"You!\" gasped Harry. Quirrell smiled. His face wasn't twitching at all. \"Me,\" he said calmly. \"I wondered whether I'd be meeting you here, Potter.\" \"But I thought -- Snape --\" \"Severus?\" Quirrell laughed, and it wasn't his usual quivering treble, either, but cold and sharp. \"Yes, Severus does seem the type, doesn't he? So useful to have him\n",
      "\n",
      "\u001b[4m\u001b[1mQuestion: Who is Bellatrix Lestrange?\u001b[0m\n",
      "\u001b[1m\u001b[92m Answer: \u001b[0mHarry Potter\n"
     ]
    }
   ],
   "source": [
    "# Answer a questions that is OUT of the scope\n",
    "client.connect()\n",
    "if __name__ == \"__main__\" and client.is_ready():\n",
    "  questionNo = 7\n",
    "  answer = answer_question(questions[questionNo])\n",
    "  print(\"\")\n",
    "  print(f\"{bcolors.UNDERLINE + bcolors.BOLD}Question: {questions[questionNo]}{bcolors.ENDC}\")\n",
    "  print(f\"{bcolors.BOLD + bcolors.OKGREEN} Answer: {bcolors.ENDC}{answer}\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- Weaviate as a vector databases has performed well retrieving chunks relates to the query provided by the user.\n",
    "- We have used 3 different models to evaluate the query and return an answer, on the first model the answer was short and austere so is hard to measure the results. For the second model we saw a similar approach.\n",
    "- On the third model we saw a significant change with the answers provided, however the model was not able to provide accurate answers on most of the cases, neither to handle questions totally out of the scope, but is important to mention in this point that I dind't provide fake answers.\n",
    "- Perhaps, we could try to improve the prompt or/and the question, tune the params of the model or prove with different models for better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
